---
aliases:
  - 모놀리식 아키텍처 -> MSA 로 전환기
---
## 기존 아키텍처 

### 기존 아키텍처 설명
![[Pasted image 20250217230619.png]]

#### 애플리케이션은 어떻게 구성되어 있나요?
기존 아키텍처는 **모놀로식** 구조로 이루어진 Spring 애플리케이션이다.
적은 트래픽을 예상한 서비스이고 애플리케이션에 존재하는 도메인들은 **서로 연관성이 높은 도메인들이다.** <br> 따라서 작은 서비스에 효율적이고 당시 팀원들의 수준으로도 구현 가능하고 , 빠른 개발과 프로젝트의 낮은 복잡도를 가질 수 있는  **모놀로식 구조를 선택했다**  . 
<br>
#### 데이터는 어떻게 저장되나요?
그리고 연관성이 높은 도메인들이어서 데이터들 또한 서로 의존도가 높다. 따라서 데이터의 관계를 현성하기 쉽고 안정성이 높은 RDB를 그중에서 **팀원들의 러닝 커브를 고려해 모두가 사용할 수 있는 MySQL을 선정하였다.**
<br>
#### 서비스 애플리케이션이 세션을 관리하나요?
데이터의 캐싱과 Spring 애플리케이션에서 refresh token 같은 사용자의 상태를 저장하고 있었지만 최소한의 서버로 운영하기 때문에 Spring 애플리케이션의 자원이 넉넉하지 않았다.
<br> 따라서 **특정한 시점**(도메인 특성상 많이 몰리는 시기)에 스케일 아웃을 염두하고 설계하였다. 이러한 구조에서 Spring 애플리케이션이 **상태(State)를 가지는 것은 확장성에 제한이** 간다고 판단하였다.
<br> 이러한 판단으로 글로벌 캐시를 구비하였고 캐시 툴 중에 스프링과 호환이 잘되고, 러닝커브가 높지 않으며 In-Memory DB로 **빠른 액세스를 보장하는 Redis를 선택하였다.**
<br>
#### 이미지 파일은 어떻게 관리하나요? 
**이미지 파일은** Byte 의 크기 자체가 일반적인 String , Int data의 Byte 크기에 비해 엄청 큰 크기를 차지한다. <br> 이러한 이미지 파일 데이터를 RDB에 저장하면 통신과 데이터를 저장하는 비용이 커서 다른 데이터 쿼리에 영향을 준다.<br> 그렇다고 Spring 애플리케이션 파일 시스템에 저장하는 것도 Spring 에 비용을 부담을 해야하고 클라이언트가 Spring 에 파일을 업로드 하는 것 또한 큰 비용이다.<br> <br> 따라서, **S3(AWS 스토리지 서비스)** 를 저장 위치로 삼았고, Spring 애플리케이션에 업로드 비용을 부담하지 않기 위해 *Presigned-URL* 을 사용해 비교적 안전한 방법으로 클라이언트가 S3에 업로드하도록 했다.  

그리고 도메인 특성에 따라 이미지 파일을 공개 돼도 상관없었다.

#### 가용성을 어떻게 보장하나요?

##### 서비스의 가용성
위에서 설명했듯이 Spring 애플리케이션은 평소에는 트래픽이 없지만 특정 기간에 트래픽이 증가하는 추이를 보이기 때문에 이에 대응하기 위해 **스케일링을 구상했다.**  <br>
트래픽의 차이가 심하기 때문에 스케일 업은 비용만 많이 들고 한계점이 명확한 선택지라고 판단했다. 따라서 정해진 기간에만 확장하는 스케일 아웃을 선택했고, 리버스 프록시를 앞에다 두었다.
<br> **리버스 프록시는** 스케일 아웃한 Spring 애플리케이션을 클라이언트의 요청을 로드 밸런싱을 위함이고 Spring 같은 애프리케이션을 공인 IP 로 노출하지 않아도 된다는 점에서 채택하였다.<br>  툴은 리버스 프록시로 많이 사용하고,  러닝커브가 낮은 **웹 서버인 Nginx를 사용하였다.**



#### Observbility는 어떻게 구현했나요?

##### 기술 스택
Spring Boot Actuator와 호환이 잘되는 prometheus 그리고 호환이 잘되고 오픈되어 있는 라이브러리가 많은 Grafana 시각화 툴을 사용하였다. <br>
그리고 로그를 저장하고 쿼리를 하기 위해 로그 저장 툴인 Loki를 사용했다.


#### 배포 파이프라인은 어떻게 구성했나요

##### CI/CD 툴
해당 서비스는 하나의 코드 베이스에서 개발되고 모든 도메인이 하나의 파이프라인에서 빌드,테스트 되며 배포된다. <br> 따라서, 무료 툴이며 러닝커브가 낮은 **github에서 제공하는 git action을 사용했다**

##### CI/CD 파이프라인
![[Pasted image 20250218015903.png]]

**Gitflow는** Vincent Driessen의 branching model을 적용해  feature - develop (dev) - release - hotfix - master 단계로 브랜치를 나눠 코드를 관리하는 전략을 사용했다. <br> 이에 맞게 devlop 브랜치와 master 브랜치에는 CD 파이프라인을 적용해 docker 이미지화 시키고 파일을 각 (dev,prod) 서버에 업로드하여 컨테이너를 실행하는 방식을 채택했다.

----

### 기존 아키텍처의 문제점

#### 추가되는 도메인
현재 아키텍처는 초기의 구상했던 서비스만을 위한 아키텍처이며, 현재 도메인에 최대한 합리적인 구조이다. <br> 하지만 **스트리밍 서비스**와 **위치기반 이벤트 서비스** **AI 요약 서비스**가 추가로 생길 예정이다. 
기존 서비스와 다르게 크고 그리고 도메인 적으로 연관성이 적은 서비스가 여러개가 추가될 예정이다.
##### 그냥 모놀리식으로 구현하면 안되나?

기존 모놀리식 서비스에 추가될 서비스를 같이 개발 && 배포 주기를 가져도 상관은 없다. 하지만, 다음 문제점을 예상하였다.

#### 서비스가 점차 추가됨으로써 문제점

##### SPOF

연관성이 적은 서로 다른 서비스가 *동일한 애플리케이션에 개발,배포,운영된다*. <br> 이러한 구조는 서로 다른 모든 서비스의 **단일 장애 지점 (SPOF)** 이다.<br>
만약 스트리밍 서비스에서 장애가 발생한다면, 게시판 서비스, 위치 기반 서비스 모두 장애가 발생하게 된다.

##### 독립적 확장의 제약

기존 구조에서는 확장을 하기위해 **Scale-Out(수평 확장)** 을 **로드밸런서(리버스 프록시)** 를 이용하여 구현하였다. *그럼 해결했나?*
<br> 서비스를 추가됨으로써 기존 확장구조에는 한계가 존재한다. <br> 스트리밍 서비스는 리소스를 많이 사용하는 대신, 특정 기간에만 운영한다. 해당 서비스를 위해서 기존 방식대로 확장을 하면 다른 서비스도 같이 확장된다. <br> *스트리밍 서비스 확장만 준비하면 되는데 모놀리식 구조는 독립적인 확장이 불가능하다는 한계점이 존재한다.* 

##### 종속적인 개발 - 배포 - 운영 파이프라인
![[Pasted image 20250218140716.png]]

처음에는 모놀로식 구조는 복잡도는 낮고 개발 난이도도 쉬우며 테스트, 배포 , 파이프라인을 간단하게 가져갈 수 있었다. <br> 하지만 서비스의 수와 크기가 커진다면 **개발 - 배포 - 운영 파이프라인이 서로 종속적이며** *개발 속도의 지연 , 테스트 속도 지연, 종속적인 배포에 나오는 늦은 서비스 배포를 야기할 것이다.*


## MSA로 전환에 대한 고찰 

 ![[Pasted image 20250218150452.png]]

### 무엇이 달라졌나?

#### 독립적인 개발 - 테스트 - 배포 - 운영
이제 독립적으로 개발, 테스트, 배포 파이프라인, 운영을 할 수 있게 된다. <br>
이로써 서로 다른 개발 팀의 의존이 줄어들고 빠른 테스팅과 배포가 가능해졌다.

#### 독립적인 확장
서비스는 원하는 자원만큼 다른 서비스와는 독립적으로 확장이 가능해졌다. <br>
DB 또한 서비스마다 다른 DB를 의존할 수 있게 되었다. 따라서 서비스마다 사용하는 DB를 다르게 사용 가능하고 확장도 독립적으로 가능하게 되었다.

#### Service Mesh의 추가

마이크로 서비스는 그냥 작은 서비스 별로 분리만 하면 장땡일까? <br>
서비스가 늘어나고 각 서비스마다 확장이 이루어진다(특정 서비스는 특정 시점에 빠른 확장을 원할 수 있다). <br> 하지만 서비스를 늘리고 각 서비스를 확장할 때마다 호스팅 서버는 추가되고 물리적 IP 주소 또한 추가 될것이다. <br>
기존 서비스처럼 전통적인 로드밸런서로 클라이언트의 요청을 라우팅한다면 만약 해당 주소로 라우팅을 지원하기 위해 라우팅 구성 파일을 수정해야 한다.<br>  만약 서비스들의 물리주소가 가변적이라면 이러한 수정이 자주 발생할 것이다. *이러한 구조는 확장에 제약을 야기한다*<br>
이렇게 서비스 컴포넌트 끼리 혹은 클라이언트 와 서비스 사이의 통신을 도와주는 **컴포넌트인 Service Mesh**를 추가하게 되었다.
[서비스 메쉬(service mesh) 개념, 기능, 방법 및 관리](https://www.redhat.com/ko/topics/microservices/what-is-a-service-mesh)

>Service Mesh 종류로는 Service Discovery(Netflix Eureka) Config(Spring Cloud Config,DB:Github)
>Service Gateway (Spring Cloud Gateway) 를 사용했다.
>해당 기술 스택을 고른 이유는 Spring 과의 호환성이며 비교적 낮은 러닝커브 때문이다. 


---

### MSA는 만능인가? (MSA의 단점)

#### 높아진 러닝커브

모놀리식 아키텍처는 개발부터 전체적인 시스템 아키텍처까지 이해하기 쉽다. 실제로 학교 프로젝트 특성상 백엔드 개발 경력이 얼마 안되는 팀원들이 대부분이다. <br>
모놀리식 아키텍처였을 땐 프로젝트의 러닝커브는 고려 대상이 아니었다. 하지만 MSA로 전환하면서 *모듈화된 코드 베이스, 늘어난 컴포넌트, 분산되어 있는 서비스들은 러닝커브가 전보다 늘어나게 된다*.

#### 해결되지 않은 복잡도
모놀리식 구조에서는 서비스가 커지고 많아지면서 생기는 서비스끼리 의존성이 강하게 생겨서 생기는 복잡도가 문제였다. <br> 그래서, MSA로 서비스를 분리하면서 인스턴스 안에 서비스 끼리 의존성은 분리되어서 개발-배포의 복잡도는 낮아졌다. 하지만 다른 복잡도는 증가하게 된다.
<br>
##### 늘어난 컴포넌트
위에서 설명했듯이 Service 와 Service Mesh 들의 수가 증가하였다.  이러한 컴포넌트들은 관리의 대상이다. 기존 모놀리식 아키텍처에서는 Spring Application 과 DB만 관리하면 됐었다. <br> **하지만 MSA로 전환하면서 그보다 몇 배 많은 컴포넌트를 관리해야한다.**

<br>
##### 분산 애플리케이션에서 발생하는 추적 난이도
위에서 언급한 늘어난 컴포넌트 전부 모니터링 대상이다. 기존에는 Spring(모놀리식 서비스), MySQL , Redis 만을 모니터링했다. 
<br>
이젠 Service Mesh와 늘어난 DB들 그리고 분산된 서비스들을 모니터링 해야한다.
그리고 **서비스 애플리케이션은 Gateway로 부터 호출되어 서로 다른 서비스끼리 호출이 생길 수 있다** (기존 client - server 구조와는 다르게 서비스로부터 요청이 올 수 있다) <br> <br> 이러한 구조에서 로깅 난이도는 증가한다.

#### 없어지지 않는 SPOF
서비스들이 하나의 애플리케이션에서 배포되지 않아 하나의 서비스가 다른 서비스에 장애를 전파시키는 현상은 줄어들어 서비스 애플리케이션의 SPOF 는 없어졌다.
<br> 하지만 마이크로서비스를 위한 컴포넌트들인 Service Mesh 같은 컴포넌트들이 SPOF가 된다. **이러한 컴포넌트들의 가용성을 위해 장애대응(failover), 가용성 등을 고려해야할 것이다.**

#### 비용
학생이라면 무조건 적으로 고려해야한다. 컴포넌트들이 증가 함에 따라 호스팅 서버도 증가한다. 물론 각 컴포넌트들이 비싼 비용을 치루지는 않는다.(비싼 리소스 자원을 요구하는 서비스만 확장 가능하기에)<br> 하지만 아무리 싼 자원으로 할당해도 기존 구조에서 수가 증가에 따른 비용 증가는 발생한다. 

---

### MSA로 전환 하려는 이유

#### 확장에 초점
지금 운영하는 서비스는 서비스가 확장을 하는 시기이다. 팀의 규모도  프로젝트에 추가되는 팀원도 확장이 되는 시기이다. **따라서 확장에 이점이 강한 MSA가 매력적이었다.** 

#### 서비스 분리
위에서 설명한 늘어나는 복잡도, 비용 그리고 러닝커브를 감수하더라도 개발과 배포에 관점에서 서비스의 분리가 이점으로 다가왔다.

#### 학습
러닝커브가 늘어나는 것은 오히려 학생에 입장에서 매력적이게 다가왔다. 컴포넌트들이 증가함에 따라 분산 트랜잭션, 상관관계 ID , 다른 컴포넌트의 가용성, failover 등 고민할 거리가 증가하였다.


---

### MSA 전환을 위해 고려할 점 및 해결해야 할 숙제

#### 코드베이스 분리? 라이브러리화? 모듈화?

##### 문제  인식
기존 코드는 단일 모듈 프로젝트로 구성되어 있다. 이렇게 구성된 이유는 서비스가 단 하나의 서비스이기 때문이므로 불필요한 복잡도를 늘리지 않기 위함이었다.
<br>
하지만 프로젝트가 분리되면서 고민이 생긴다 코드베이스를 완전히 분리하여 서로 다른 코드베이스에서 개발할지 아니면 모듈화를 시킬지에 대한 고민이다.
<br>
-> **횡단 관심사** 

해당 서비스들은 모니터링과 보안, 외부 컴포넌트 설정 등 모든 서비스에 동일해야 하는 횡단 관심사가 존재한다. <br>
따라서 완전한 코드베이스 분리는 이러한 횡단 관심사를 일일히 구현 해야하는 숙제가 된다.

##### 문제 해결책

1. Monolith Architecture->  Modular Monolith Architecture -> MSA?




#### SPOF 컴포넌트의 가용성
##### 문제  인식

Service Mesh 컴포넌트들의 가용성과 Redis 같은 컴포넌트의 가용성을 오버 엔지니어링만 되지 않게 생각해야한다.

##### 문제 해결책



#### CI/CD 파이프라인
##### 문제  인식
서비스가 분리됨에 따라 각 서비스마다 독립적인 CI/CD 파이프라인을 가져야 한다.

##### 문제 해결책
1. Action으로만 해결 가능한가?
2. Jenkins를 기술 스택으로 추가해야하나?
#### 모니터링
##### 문제  인식
분산된 애플리케이션을 모니터링 할 수 있도록 해야한다.

##### 문제 해결책
- 추적을 위해 상관관계 ID
